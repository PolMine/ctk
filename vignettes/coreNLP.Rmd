---
title: "Corpus Preparation using CoreNLP"
author: "Andreas BlÃ¤tte (andreas.blaette@uni-due.de)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Corpus Preparation using CoreNLP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Setting parameters and global variables

The java.parameters need to be set before loading the packages: A JVM is initialized when ctk imports from then openNLP package, and if the JVM is not provided with sufficient memory on this occasion, the later initialization of corenlp will hit the memory limit.
  
```{r}
options(java.parameters = "-Xmx4g")  
stanfordDir = "/opt/stanford-corenlp/stanford-corenlp-full-2017-06-09"
propertiesFile = "/opt/stanford-corenlp/StanfordCoreNLP-german.properties"
```

```{r}
filenames <- Sys.glob(sprintf("%s/*.xml", "~/Lab/gitlab/plprbttxt_tei"))
filenames <- filenames[1:2]
```

```{r}
noCores <- parallel::detectCores() - 1
```


# Loading required packages

```{r}
library(ctk)
library(data.table)
library(magrittr)
library(xml2)
library(stringi)
library(rJava)
library(pbapply)
library(parallel)
library(readr)
library(text2vec)
```


# Generate data.table

```{r}
metadata <- c(
  lp = "//legislativePeriod",
  session = "//titleStmt/sessionNo",
  date = "//publicationStmt/date"
)
```


```{r}
dtList <- pbapply::pblapply(filenames, function(x) xmlToDT(x, meta = metadata), cl = noCores)
dt <- rbindlist(dtList, fill = TRUE)
rm(dtList)
```

Some beautification ...

```{r}
dt2 <- dt[is.na(speaker)][, speaker := NULL] # remove text in speaker tag
dt2[, chunk := 1:nrow(dt2)] # add column with chunks
for (x in c("div_what", "div_desc", "body", "TEI", "p")) dt2[[x]] <- NULL
dt2[["stage_type"]] <- ifelse(is.na(dt2[["stage_type"]]), "speech", "interjection")
rm(dt)
```

We will continue to work with dt2


# Annotation: Without parallelization

Initialize annotator

```{r}
CNLP <- CoreNLP$new(
  method = "json", filename = "~/Lab/tmp/coreNLP.json",
  stanfordDir = stanfordDir, propertiesFile = propertiesFile
  )
```

```{r}
dummy <- pbapply::pblapply(
  1:nrow(dt2),
  function(i) CNLP$annotate(dt2[["text"]][i], chunk = i) # add chunks for matching with metadata table
)
```

```{r}
J <- readr::read_lines(file = "~/Lab/tmp/coreNLP.json", progress = TRUE)
```

```{r}
dts <- pbapply::pblapply(J, CNLP$parseJson) # parallelization works nicely here
tokenStreamDT <- rbindlist(dts)
```


# With parallelization

processing 1100 plenary protocols ~ 2h 

```{r}
chunks <- text2vec::split_into(1:nrow(dt2), n = noCores)
started <- Sys.time()
filenames <- parallel::mclapply(
  1:length(chunks),
  function(i){
    options(java.parameters = "-Xmx4g")
    filename <- sprintf("~/Lab/tmp/coreNLP_%d.json", i)
    A <- CoreNLP$new(
      method = "json", filename = filename,
      stanfordDir = stanfordDir, propertiesFile = propertiesFile
      )
    lapply(chunks[[i]], function(j) A$annotate(dt2[["text"]][j], chunk = j))
    return( filename )
  },
  mc.cores = noCores
)
ended <- Sys.time()
ended - started
```


```{r}
J <- unlist(lapply(filenames, readr::read_lines))
```


```{r}
CNLP <- CoreNLP$new(method = "json")
dts <- pbapply::pblapply(J, CNLP$parseJson, cl = noCores) # parallelization works nicely here
tokenStreamDT <- rbindlist(dts)
```


# Turn data.table into a CWB indexed corpus

```{r}
tokenStreamDT[, cpos := 0:(nrow(tokenStreamDT) - 1)]
```

Encode the p-attributes ("word" and "pos", so far).

```{r}
encode(tokenStreamDT[["token"]], corpus = "FOO", pAttribute = "word", encoding = "UTF-8")
encode(tokenStreamDT[["pos"]], corpus = "FOO", pAttribute = "pos")
```

Encode the s-attributes.

```{r}
cpos <- tokenStreamDT[
  ,{list(cpos_left = min(.SD[["cpos"]]), cpos_right = max(.SD[["cpos"]]))}, by = "chunk"
  ]
setkeyv(cpos, cols = "chunk")
setkeyv(dt2, cols = "chunk")
dt3 <- dt2[cpos]
options("polmineR.cwb-regedit" = FALSE)
setnames(dt3, old = c("sp_party", "sp_name"), new = c("party", "name"))
```

```{r}
for (col in c("party", "name", "lp", "session", "date")){
  dtEnc <- dt3[, c("cpos_left", "cpos_right", col), with = FALSE]
  encode(dtEnc, corpus = "FOO", sAttribute = col)
}
```

```{r}
use()
```